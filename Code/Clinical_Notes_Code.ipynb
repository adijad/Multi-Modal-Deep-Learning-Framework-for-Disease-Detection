{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9911157,"sourceType":"datasetVersion","datasetId":6089787},{"sourceId":10095369,"sourceType":"datasetVersion","datasetId":6209778}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install numpy opencv-python","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ncsv_path = '/kaggle/input/report-dataset/full_report_data.csv'\nfull_data = pd.read_csv(csv_path)\nprint(full_data.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T17:21:13.634677Z","iopub.execute_input":"2024-12-09T17:21:13.635035Z","iopub.status.idle":"2024-12-09T17:21:15.154678Z","shell.execute_reply.started":"2024-12-09T17:21:13.635004Z","shell.execute_reply":"2024-12-09T17:21:15.153861Z"}},"outputs":[{"name":"stdout","text":"  subject_id   study_id                                        examination  \\\n0  p18726783  s54132939  Evaluation of the patient after ICD placement ...   \n1  p18726783  s54838151                                                NaN   \n2  p18726783  s55647339    Evaluation of the patient with nausea, dysuria.   \n3  p18726783  s55239487                                                NaN   \n4  p18726783  s53461826    Evaluation of the patient with congestive heart   \n\n                                          indication  \\\n0                                                NaN   \n1  NSTEMI, residual shortness of breath, changes ...   \n2                                                NaN   \n3                                                NaN   \n4                                                NaN   \n\n                            technique                           comparison  \\\n0                                 NaN                                  NaN   \n1                                 NaN                                 ___.   \n2                                 NaN                                  NaN   \n3  PA and lateral views of the chest.  ___ chest radiograph ___ chest CTA.   \n4                                 NaN                                  NaN   \n\n                                            findings  \\\n0                                                NaN   \n1                                                NaN   \n2                                                NaN   \n3  The heart remains moderately enlarged.  The ao...   \n4                                                NaN   \n\n                                          impression  \n0                                                NaN  \n1                                                NaN  \n2                                                NaN  \n3  Small bilateral pleural effusions, left greate...  \n4                                                NaN  \n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# # Replace all NaN values with 0\n# mimic_data.fillna(0, inplace=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mimic_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T17:22:04.085409Z","iopub.execute_input":"2024-12-09T17:22:04.085776Z","iopub.status.idle":"2024-12-09T17:22:04.109971Z","shell.execute_reply.started":"2024-12-09T17:22:04.085744Z","shell.execute_reply":"2024-12-09T17:22:04.109151Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"        subject_id  study_id  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n0         10000032  50414267          NaN           NaN            NaN    NaN   \n1         10000032  53189527          NaN           NaN            NaN    NaN   \n2         10000032  53911762          NaN           NaN            NaN    NaN   \n3         10000032  56699142          NaN           NaN            NaN    NaN   \n4         10000764  57375967          NaN           NaN            1.0    NaN   \n...            ...       ...          ...           ...            ...    ...   \n227822    19999442  58708861          NaN           NaN            NaN    NaN   \n227823    19999733  57132437          NaN           NaN            NaN    NaN   \n227824    19999987  55368167          1.0          -1.0            NaN    NaN   \n227825    19999987  58621812          1.0           NaN            NaN    NaN   \n227826    19999987  58971208          1.0           NaN            NaN    NaN   \n\n        Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n0                              NaN       NaN          NaN           NaN   \n1                              NaN       NaN          NaN           NaN   \n2                              NaN       NaN          NaN           NaN   \n3                              NaN       NaN          NaN           NaN   \n4                              NaN       NaN          NaN           NaN   \n...                            ...       ...          ...           ...   \n227822                         NaN       NaN          NaN           NaN   \n227823                         NaN       NaN          NaN           NaN   \n227824                         NaN       NaN          0.0           NaN   \n227825                         NaN       NaN          NaN           NaN   \n227826                         NaN       NaN          NaN           NaN   \n\n        No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n0              1.0               NaN            NaN        NaN           NaN   \n1              1.0               NaN            NaN        NaN           NaN   \n2              1.0               NaN            NaN        NaN           NaN   \n3              1.0               NaN            NaN        NaN           NaN   \n4              NaN               NaN            NaN       -1.0           NaN   \n...            ...               ...            ...        ...           ...   \n227822         1.0               NaN            NaN        NaN           NaN   \n227823         1.0               NaN            NaN        NaN           NaN   \n227824         NaN               0.0            NaN        NaN           0.0   \n227825         NaN               NaN            NaN        NaN           NaN   \n227826         NaN               NaN            NaN        NaN           NaN   \n\n        Support Devices  \n0                   NaN  \n1                   NaN  \n2                   NaN  \n3                   NaN  \n4                   NaN  \n...                 ...  \n227822              1.0  \n227823              NaN  \n227824              NaN  \n227825              1.0  \n227826              NaN  \n\n[227827 rows x 16 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>study_id</th>\n      <th>Atelectasis</th>\n      <th>Cardiomegaly</th>\n      <th>Consolidation</th>\n      <th>Edema</th>\n      <th>Enlarged Cardiomediastinum</th>\n      <th>Fracture</th>\n      <th>Lung Lesion</th>\n      <th>Lung Opacity</th>\n      <th>No Finding</th>\n      <th>Pleural Effusion</th>\n      <th>Pleural Other</th>\n      <th>Pneumonia</th>\n      <th>Pneumothorax</th>\n      <th>Support Devices</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10000032</td>\n      <td>50414267</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10000032</td>\n      <td>53189527</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10000032</td>\n      <td>53911762</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10000032</td>\n      <td>56699142</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10000764</td>\n      <td>57375967</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>227822</th>\n      <td>19999442</td>\n      <td>58708861</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>227823</th>\n      <td>19999733</td>\n      <td>57132437</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>227824</th>\n      <td>19999987</td>\n      <td>55368167</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>227825</th>\n      <td>19999987</td>\n      <td>58621812</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>227826</th>\n      <td>19999987</td>\n      <td>58971208</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>227827 rows Ã— 16 columns</p>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, roc_curve\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nclass TextDataset(Dataset):\n    def __init__(self, embeddings, labels):\n        self.embeddings = embeddings\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.embeddings)\n\n    def __getitem__(self, idx):\n        return self.embeddings[idx], self.labels[idx]\n\nclass MultilabelFocalLoss(nn.Module):\n    def __init__(self, gamma=2, weights=None, epsilon=1e-7):\n        super().__init__()\n        self.gamma = gamma\n        self.weights = weights\n        self.epsilon = epsilon\n\n    def forward(self, inputs, targets):\n        inputs = torch.clamp(inputs, self.epsilon, 1 - self.epsilon)\n        loss = -targets * torch.log(inputs) - (1 - targets) * torch.log(1 - inputs)\n        pt = torch.exp(-loss)\n        focal_loss = (1-pt)**self.gamma * loss\n        if self.weights is not None:\n            focal_loss = focal_loss * self.weights.unsqueeze(0)\n        return focal_loss.mean()\n\nclass LSTMClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2):\n        super().__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True, dropout=0.3)\n        self.attention = nn.Sequential(\n            nn.Linear(hidden_dim * 2, 1),\n            nn.Softmax(dim=1)\n        )\n        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n\n    def forward(self, x):\n        x = x.unsqueeze(1)\n        lstm_out, _ = self.lstm(x)\n        attention_weights = self.attention(lstm_out)\n        context = torch.sum(attention_weights * lstm_out, dim=1)\n        return torch.sigmoid(self.fc(context))\n\ndef process_in_batches(X, tokenizer, model, batch_size=32):\n    embeddings = []\n    model.eval()\n    for i in tqdm(range(0, len(X), batch_size), desc=\"Generating embeddings\"):\n        batch = X[i:i + batch_size].tolist()\n        tokens = tokenizer(batch, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n        tokens = {k: v.to(device) for k, v in tokens.items()}\n        with torch.no_grad():\n            outputs = model(**tokens)\n            batch_embeddings = outputs.last_hidden_state.mean(dim=1)\n            embeddings.append(batch_embeddings.cpu().numpy())\n    return np.vstack(embeddings)\n\ndef calculate_class_weights(y):\n    weights = []\n    for col in y.columns:\n        counts = y[col].value_counts()\n        neg = len(y[y[col] <= 0])\n        pos = len(y[y[col] > 0])\n        weights.append(neg/pos if pos > 0 else 1.0)\n    return torch.FloatTensor(weights).to(device)\n\ndef train_and_evaluate_lstm(X_train, X_test, y_train, y_test, input_dim, hidden_dim, output_dim,\n                          tokenizer, bert_model, conditions, batch_size=32, epochs=15, learning_rate=0.001):\n    print(\"Processing embeddings...\")\n    X_train_emb = process_in_batches(X_train, tokenizer, bert_model, batch_size)\n    X_test_emb = process_in_batches(X_test, tokenizer, bert_model, batch_size)\n\n    train_dataset = TextDataset(torch.tensor(X_train_emb, dtype=torch.float32),\n                              torch.tensor(y_train.values, dtype=torch.float32))\n    test_dataset = TextDataset(torch.tensor(X_test_emb, dtype=torch.float32),\n                             torch.tensor(y_test.values, dtype=torch.float32))\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n    model = LSTMClassifier(input_dim=input_dim, hidden_dim=hidden_dim,\n                          output_dim=output_dim).to(device)\n\n    class_weights = calculate_class_weights(y_train)\n    criterion = MultilabelFocalLoss(gamma=4, weights=class_weights)\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n\n    best_val_f1 = 0.0\n    best_model_state = None\n    train_losses = []\n\n    for epoch in range(epochs):\n        model.train()\n        epoch_loss = 0\n        for batch_emb, batch_labels in train_loader:\n            batch_emb, batch_labels = batch_emb.to(device), batch_labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(batch_emb)\n            loss = criterion(outputs, batch_labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            epoch_loss += loss.item()\n\n        train_losses.append(epoch_loss)\n\n        # Validation phase\n        model.eval()\n        val_preds, val_true = [], []\n        with torch.no_grad():\n            for batch_emb, batch_labels in test_loader:\n                batch_emb, batch_labels = batch_emb.to(device), batch_labels.to(device)\n                outputs = model(batch_emb)\n                val_preds.extend(outputs.cpu().numpy())\n                val_true.extend(batch_labels.cpu().numpy())\n\n        val_preds = np.array(val_preds)\n        val_true = np.array(val_true)\n        val_preds_binary = (val_preds > 0.5).astype(int)\n\n        # Calculate overall metrics\n        overall_accuracy = accuracy_score(val_true, val_preds_binary)\n        overall_precision, overall_recall, overall_f1, _ = precision_recall_fscore_support(\n            val_true, val_preds_binary, average='macro', zero_division=0)\n\n        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n        print(f\"Loss: {epoch_loss:.4f}\")\n        print(\"\\nOverall Metrics:\")\n        print(f\"  Accuracy: {overall_accuracy:.4f}\")\n        print(f\"  Precision: {overall_precision:.4f}\")\n        print(f\"  Recall: {overall_recall:.4f}\")\n        print(f\"  F1: {overall_f1:.4f}\")\n\n        # Per-condition metrics\n        print(\"\\nPer-condition Metrics:\")\n        for i, condition in enumerate(conditions):\n            accuracy = accuracy_score(val_true[:, i], val_preds_binary[:, i])\n            precision, recall, f1, _ = precision_recall_fscore_support(\n                val_true[:, i], val_preds_binary[:, i], average='binary', zero_division=0)\n\n            if len(np.unique(val_true[:, i])) > 1:\n                roc_auc = roc_auc_score(val_true[:, i], val_preds[:, i])\n            else:\n                roc_auc = 0\n\n            print(f\"{condition}:\")\n            print(f\"  Accuracy: {accuracy:.4f}\")\n            print(f\"  Precision: {precision:.4f}\")\n            print(f\"  Recall: {recall:.4f}\")\n            print(f\"  F1: {f1:.4f}\")\n            print(f\"  ROC AUC: {roc_auc:.4f}\")\n\n        if overall_f1 > best_val_f1:\n            best_val_f1 = overall_f1\n            best_model_state = model.state_dict()\n\n        scheduler.step(overall_f1)\n\n    # Plot loss curve\n    plt.figure(figsize=(10, 5))\n    plt.plot(train_losses)\n    plt.title('Training Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.savefig('loss_curve.png')\n    plt.close()\n\n    # Final evaluation with best model\n    model.load_state_dict(best_model_state)\n    model.eval()\n    final_preds, final_true = [], []\n\n    with torch.no_grad():\n        for batch_emb, batch_labels in test_loader:\n            batch_emb = batch_emb.to(device)\n            outputs = model(batch_emb)\n            final_preds.extend(outputs.cpu().numpy())\n            final_true.extend(batch_labels.cpu().numpy())\n\n    final_preds = np.array(final_preds)\n    final_true = np.array(final_true)\n    final_preds_binary = (final_preds > 0.5).astype(int)\n\n    # Save ROC curves\n    plt.figure(figsize=(10, 8))\n    for i, condition in enumerate(conditions):\n        if len(np.unique(final_true[:, i])) > 1:\n            fpr, tpr, _ = roc_curve(final_true[:, i], final_preds[:, i])\n            roc_auc = roc_auc_score(final_true[:, i], final_preds[:, i])\n            plt.plot(fpr, tpr, label=f'{condition} (AUC = {roc_auc:.2f})')\n\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curves')\n    plt.legend()\n    plt.savefig('roc_curves.png')\n    plt.close()\n\n    return model, best_val_f1\n\ndef main():\n    print(\"Loading data...\")\n    csv_path_full = '/kaggle/input/report-dataset/full_report_data.csv'\n    csv_path_mimic = '/kaggle/input/dlproject/mimic-cxr-2.0.0-chexpert.csv'\n\n    full_data = pd.read_csv(csv_path_full)\n    conditions = ['Atelectasis', 'Pneumonia', 'Edema']\n    mimic_data = pd.read_csv(csv_path_mimic, usecols=['subject_id'] + conditions)\n\n    full_data['subject_id'] = full_data['subject_id'].str.lstrip('p').astype(int)\n    mimic_data['subject_id'] = mimic_data['subject_id'].astype(int)\n\n    valid_indices = ~mimic_data[conditions].isin([-1]).any(axis=1)\n    mimic_data = mimic_data[valid_indices]\n\n    required_columns = ['examination', 'indication', 'findings', 'impression']\n    filtered_data = full_data.dropna(subset=required_columns, how='any')\n    filtered_data = filtered_data[filtered_data[required_columns].ne('').all(axis=1)]\n\n    merged_data = pd.merge(filtered_data, mimic_data, on='subject_id', how='inner')\n    merged_data = merged_data[merged_data['subject_id'].astype(str).str.match(r'10|11')]\n\n    merged_data['combined_text'] = merged_data[required_columns].agg(' '.join, axis=1)\n\n    print(f\"Final dataset size: {len(merged_data)}\")\n    print(\"Label distribution:\")\n    for condition in conditions:\n        print(f\"{condition}:\\n{merged_data[condition].value_counts()}\\n\")\n\n    X = merged_data['combined_text']\n    y = merged_data[conditions].fillna(0)\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n    bert_model = AutoModel.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\").to(device)\n\n    input_dim = 768\n    hidden_dim = 256\n    output_dim = len(conditions)\n    batch_size = 32\n\n    model, best_f1 = train_and_evaluate_lstm(X_train, X_test, y_train, y_test, input_dim, hidden_dim, output_dim,\n                                           tokenizer, bert_model, conditions, batch_size=batch_size, epochs=25)\n\n    print(f\"\\nBest F1 Score: {best_f1:.4f}\")\n    torch.save(model.state_dict(), 'best_model.pt')\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T00:34:36.713652Z","iopub.execute_input":"2024-12-10T00:34:36.713982Z","iopub.status.idle":"2024-12-10T00:52:56.376623Z","shell.execute_reply.started":"2024-12-10T00:34:36.713954Z","shell.execute_reply":"2024-12-10T00:52:56.375713Z"}},"outputs":[{"name":"stdout","text":"Loading data...\nFinal dataset size: 78460\nLabel distribution:\nAtelectasis:\nAtelectasis\n1.0    17897\n0.0      574\nName: count, dtype: int64\n\nPneumonia:\nPneumonia\n0.0    7170\n1.0    5969\nName: count, dtype: int64\n\nEdema:\nEdema\n1.0    13073\n0.0     9297\nName: count, dtype: int64\n\nProcessing embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating embeddings:   0%|          | 0/1962 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e396b14221d542cfa95cac7b1413b13a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating embeddings:   0%|          | 0/491 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"372ab46ab67a4d28ae01dca14421f09f"}},"metadata":{}},{"name":"stdout","text":"\nEpoch 1/25\nLoss: 329.1147\n\nOverall Metrics:\n  Accuracy: 0.6029\n  Precision: 0.0000\n  Recall: 0.0000\n  F1: 0.0000\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7721\n  Precision: 0.0000\n  Recall: 0.0000\n  F1: 0.0000\n  ROC AUC: 0.6457\nPneumonia:\n  Accuracy: 0.9213\n  Precision: 0.0000\n  Recall: 0.0000\n  F1: 0.0000\n  ROC AUC: 0.6286\nEdema:\n  Accuracy: 0.8318\n  Precision: 0.0000\n  Recall: 0.0000\n  F1: 0.0000\n  ROC AUC: 0.7152\n\nEpoch 2/25\nLoss: 322.1419\n\nOverall Metrics:\n  Accuracy: 0.6036\n  Precision: 0.1770\n  Recall: 0.0076\n  F1: 0.0145\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7722\n  Precision: 0.0000\n  Recall: 0.0000\n  F1: 0.0000\n  ROC AUC: 0.6649\nPneumonia:\n  Accuracy: 0.9213\n  Precision: 0.0000\n  Recall: 0.0000\n  F1: 0.0000\n  ROC AUC: 0.6325\nEdema:\n  Accuracy: 0.8322\n  Precision: 0.5310\n  Recall: 0.0227\n  F1: 0.0436\n  ROC AUC: 0.7176\n\nEpoch 3/25\nLoss: 319.9713\n\nOverall Metrics:\n  Accuracy: 0.6027\n  Precision: 0.1616\n  Recall: 0.0075\n  F1: 0.0143\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7719\n  Precision: 0.4848\n  Recall: 0.0224\n  F1: 0.0428\n  ROC AUC: 0.6628\nPneumonia:\n  Accuracy: 0.9213\n  Precision: 0.0000\n  Recall: 0.0000\n  F1: 0.0000\n  ROC AUC: 0.6498\nEdema:\n  Accuracy: 0.8318\n  Precision: 0.0000\n  Recall: 0.0000\n  F1: 0.0000\n  ROC AUC: 0.7242\n\nEpoch 4/25\nLoss: 318.1301\n\nOverall Metrics:\n  Accuracy: 0.6030\n  Precision: 0.0000\n  Recall: 0.0000\n  F1: 0.0000\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7722\n  Precision: 0.0000\n  Recall: 0.0000\n  F1: 0.0000\n  ROC AUC: 0.6702\nPneumonia:\n  Accuracy: 0.9213\n  Precision: 0.0000\n  Recall: 0.0000\n  F1: 0.0000\n  ROC AUC: 0.6518\nEdema:\n  Accuracy: 0.8318\n  Precision: 0.0000\n  Recall: 0.0000\n  F1: 0.0000\n  ROC AUC: 0.7280\n\nEpoch 5/25\nLoss: 316.4347\n\nOverall Metrics:\n  Accuracy: 0.6034\n  Precision: 0.4089\n  Recall: 0.0018\n  F1: 0.0036\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7724\n  Precision: 0.5600\n  Recall: 0.0039\n  F1: 0.0078\n  ROC AUC: 0.6724\nPneumonia:\n  Accuracy: 0.9213\n  Precision: 0.0000\n  Recall: 0.0000\n  F1: 0.0000\n  ROC AUC: 0.6546\nEdema:\n  Accuracy: 0.8319\n  Precision: 0.6667\n  Recall: 0.0015\n  F1: 0.0030\n  ROC AUC: 0.7320\n\nEpoch 6/25\nLoss: 314.9673\n\nOverall Metrics:\n  Accuracy: 0.6035\n  Precision: 0.4047\n  Recall: 0.0039\n  F1: 0.0078\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7721\n  Precision: 0.4750\n  Recall: 0.0053\n  F1: 0.0105\n  ROC AUC: 0.6768\nPneumonia:\n  Accuracy: 0.9213\n  Precision: 0.0000\n  Recall: 0.0000\n  F1: 0.0000\n  ROC AUC: 0.6606\nEdema:\n  Accuracy: 0.8325\n  Precision: 0.7391\n  Recall: 0.0064\n  F1: 0.0128\n  ROC AUC: 0.7370\n\nEpoch 7/25\nLoss: 311.0419\n\nOverall Metrics:\n  Accuracy: 0.6029\n  Precision: 0.3449\n  Recall: 0.0385\n  F1: 0.0660\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7727\n  Precision: 0.5299\n  Recall: 0.0173\n  F1: 0.0336\n  ROC AUC: 0.6781\nPneumonia:\n  Accuracy: 0.9212\n  Precision: 0.0000\n  Recall: 0.0000\n  F1: 0.0000\n  ROC AUC: 0.6601\nEdema:\n  Accuracy: 0.8321\n  Precision: 0.5049\n  Recall: 0.0981\n  F1: 0.1643\n  ROC AUC: 0.7417\n\nEpoch 8/25\nLoss: 309.9607\n\nOverall Metrics:\n  Accuracy: 0.6048\n  Precision: 0.6318\n  Recall: 0.0121\n  F1: 0.0235\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7735\n  Precision: 0.5704\n  Recall: 0.0215\n  F1: 0.0415\n  ROC AUC: 0.6823\nPneumonia:\n  Accuracy: 0.9214\n  Precision: 0.6250\n  Recall: 0.0040\n  F1: 0.0080\n  ROC AUC: 0.6636\nEdema:\n  Accuracy: 0.8328\n  Precision: 0.7000\n  Recall: 0.0106\n  F1: 0.0209\n  ROC AUC: 0.7439\n\nEpoch 9/25\nLoss: 308.3644\n\nOverall Metrics:\n  Accuracy: 0.6043\n  Precision: 0.4936\n  Recall: 0.0523\n  F1: 0.0921\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7719\n  Precision: 0.4948\n  Recall: 0.0669\n  F1: 0.1178\n  ROC AUC: 0.6858\nPneumonia:\n  Accuracy: 0.9211\n  Precision: 0.4000\n  Recall: 0.0049\n  F1: 0.0096\n  ROC AUC: 0.6666\nEdema:\n  Accuracy: 0.8360\n  Precision: 0.5859\n  Recall: 0.0852\n  F1: 0.1488\n  ROC AUC: 0.7495\n\nEpoch 10/25\nLoss: 307.3060\n\nOverall Metrics:\n  Accuracy: 0.6044\n  Precision: 0.3504\n  Recall: 0.0504\n  F1: 0.0870\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7727\n  Precision: 0.5103\n  Recall: 0.0484\n  F1: 0.0884\n  ROC AUC: 0.6845\nPneumonia:\n  Accuracy: 0.9212\n  Precision: 0.0000\n  Recall: 0.0000\n  F1: 0.0000\n  ROC AUC: 0.6655\nEdema:\n  Accuracy: 0.8344\n  Precision: 0.5409\n  Recall: 0.1027\n  F1: 0.1726\n  ROC AUC: 0.7510\n\nEpoch 11/25\nLoss: 306.0919\n\nOverall Metrics:\n  Accuracy: 0.5980\n  Precision: 0.4163\n  Recall: 0.0902\n  F1: 0.1417\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7701\n  Precision: 0.4777\n  Recall: 0.1021\n  F1: 0.1683\n  ROC AUC: 0.6881\nPneumonia:\n  Accuracy: 0.9205\n  Precision: 0.2759\n  Recall: 0.0065\n  F1: 0.0127\n  ROC AUC: 0.6633\nEdema:\n  Accuracy: 0.8313\n  Precision: 0.4954\n  Recall: 0.1621\n  F1: 0.2443\n  ROC AUC: 0.7519\n\nEpoch 12/25\nLoss: 304.9094\n\nOverall Metrics:\n  Accuracy: 0.6007\n  Precision: 0.4658\n  Recall: 0.0877\n  F1: 0.1379\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7712\n  Precision: 0.4857\n  Recall: 0.0806\n  F1: 0.1382\n  ROC AUC: 0.6880\nPneumonia:\n  Accuracy: 0.9210\n  Precision: 0.4074\n  Recall: 0.0089\n  F1: 0.0174\n  ROC AUC: 0.6628\nEdema:\n  Accuracy: 0.8323\n  Precision: 0.5044\n  Recall: 0.1735\n  F1: 0.2582\n  ROC AUC: 0.7542\n\nEpoch 13/25\nLoss: 304.0494\n\nOverall Metrics:\n  Accuracy: 0.6062\n  Precision: 0.4868\n  Recall: 0.0619\n  F1: 0.1072\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7731\n  Precision: 0.5148\n  Recall: 0.0632\n  F1: 0.1126\n  ROC AUC: 0.6885\nPneumonia:\n  Accuracy: 0.9205\n  Precision: 0.3500\n  Recall: 0.0113\n  F1: 0.0220\n  ROC AUC: 0.6665\nEdema:\n  Accuracy: 0.8378\n  Precision: 0.5955\n  Recall: 0.1110\n  F1: 0.1871\n  ROC AUC: 0.7507\n\nEpoch 14/25\nLoss: 303.2359\n\nOverall Metrics:\n  Accuracy: 0.6042\n  Precision: 0.4930\n  Recall: 0.0710\n  F1: 0.1212\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7719\n  Precision: 0.4953\n  Recall: 0.0879\n  F1: 0.1492\n  ROC AUC: 0.6896\nPneumonia:\n  Accuracy: 0.9207\n  Precision: 0.3913\n  Recall: 0.0146\n  F1: 0.0281\n  ROC AUC: 0.6652\nEdema:\n  Accuracy: 0.8376\n  Precision: 0.5923\n  Recall: 0.1106\n  F1: 0.1864\n  ROC AUC: 0.7579\n\nEpoch 15/25\nLoss: 301.7568\n\nOverall Metrics:\n  Accuracy: 0.6046\n  Precision: 0.4772\n  Recall: 0.0818\n  F1: 0.1298\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7735\n  Precision: 0.5248\n  Recall: 0.0593\n  F1: 0.1066\n  ROC AUC: 0.6906\nPneumonia:\n  Accuracy: 0.9209\n  Precision: 0.3793\n  Recall: 0.0089\n  F1: 0.0174\n  ROC AUC: 0.6653\nEdema:\n  Accuracy: 0.8349\n  Precision: 0.5276\n  Recall: 0.1773\n  F1: 0.2654\n  ROC AUC: 0.7610\n\nEpoch 16/25\nLoss: 298.6633\n\nOverall Metrics:\n  Accuracy: 0.6046\n  Precision: 0.4734\n  Recall: 0.0796\n  F1: 0.1312\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7729\n  Precision: 0.5108\n  Recall: 0.0730\n  F1: 0.1278\n  ROC AUC: 0.6934\nPneumonia:\n  Accuracy: 0.9203\n  Precision: 0.3529\n  Recall: 0.0146\n  F1: 0.0280\n  ROC AUC: 0.6704\nEdema:\n  Accuracy: 0.8369\n  Precision: 0.5565\n  Recall: 0.1511\n  F1: 0.2377\n  ROC AUC: 0.7646\n\nEpoch 17/25\nLoss: 297.1746\n\nOverall Metrics:\n  Accuracy: 0.6063\n  Precision: 0.4948\n  Recall: 0.0524\n  F1: 0.0927\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7732\n  Precision: 0.5209\n  Recall: 0.0523\n  F1: 0.0951\n  ROC AUC: 0.6945\nPneumonia:\n  Accuracy: 0.9208\n  Precision: 0.3462\n  Recall: 0.0073\n  F1: 0.0143\n  ROC AUC: 0.6689\nEdema:\n  Accuracy: 0.8380\n  Precision: 0.6172\n  Recall: 0.0977\n  F1: 0.1687\n  ROC AUC: 0.7665\n\nEpoch 18/25\nLoss: 296.6253\n\nOverall Metrics:\n  Accuracy: 0.6058\n  Precision: 0.4842\n  Recall: 0.0686\n  F1: 0.1160\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7717\n  Precision: 0.4910\n  Recall: 0.0688\n  F1: 0.1207\n  ROC AUC: 0.6952\nPneumonia:\n  Accuracy: 0.9209\n  Precision: 0.3704\n  Recall: 0.0081\n  F1: 0.0158\n  ROC AUC: 0.6678\nEdema:\n  Accuracy: 0.8385\n  Precision: 0.5913\n  Recall: 0.1288\n  F1: 0.2115\n  ROC AUC: 0.7669\n\nEpoch 19/25\nLoss: 295.4608\n\nOverall Metrics:\n  Accuracy: 0.6063\n  Precision: 0.4814\n  Recall: 0.0788\n  F1: 0.1323\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7735\n  Precision: 0.5154\n  Recall: 0.0937\n  F1: 0.1586\n  ROC AUC: 0.6931\nPneumonia:\n  Accuracy: 0.9202\n  Precision: 0.3333\n  Recall: 0.0138\n  F1: 0.0264\n  ROC AUC: 0.6670\nEdema:\n  Accuracy: 0.8387\n  Precision: 0.5954\n  Recall: 0.1288\n  F1: 0.2118\n  ROC AUC: 0.7685\n\nEpoch 20/25\nLoss: 292.9326\n\nOverall Metrics:\n  Accuracy: 0.6051\n  Precision: 0.4797\n  Recall: 0.0787\n  F1: 0.1302\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7719\n  Precision: 0.4949\n  Recall: 0.0823\n  F1: 0.1411\n  ROC AUC: 0.6975\nPneumonia:\n  Accuracy: 0.9208\n  Precision: 0.3571\n  Recall: 0.0081\n  F1: 0.0158\n  ROC AUC: 0.6653\nEdema:\n  Accuracy: 0.8390\n  Precision: 0.5869\n  Recall: 0.1458\n  F1: 0.2336\n  ROC AUC: 0.7686\n\nEpoch 21/25\nLoss: 292.6289\n\nOverall Metrics:\n  Accuracy: 0.6064\n  Precision: 0.5131\n  Recall: 0.0841\n  F1: 0.1412\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7729\n  Precision: 0.5083\n  Recall: 0.0862\n  F1: 0.1474\n  ROC AUC: 0.6976\nPneumonia:\n  Accuracy: 0.9207\n  Precision: 0.4416\n  Recall: 0.0275\n  F1: 0.0518\n  ROC AUC: 0.6663\nEdema:\n  Accuracy: 0.8388\n  Precision: 0.5894\n  Recall: 0.1386\n  F1: 0.2245\n  ROC AUC: 0.7706\n\nEpoch 22/25\nLoss: 291.9463\n\nOverall Metrics:\n  Accuracy: 0.6059\n  Precision: 0.5170\n  Recall: 0.0829\n  F1: 0.1392\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7733\n  Precision: 0.5130\n  Recall: 0.0940\n  F1: 0.1589\n  ROC AUC: 0.6991\nPneumonia:\n  Accuracy: 0.9209\n  Precision: 0.4500\n  Recall: 0.0219\n  F1: 0.0417\n  ROC AUC: 0.6672\nEdema:\n  Accuracy: 0.8385\n  Precision: 0.5879\n  Recall: 0.1330\n  F1: 0.2169\n  ROC AUC: 0.7707\n\nEpoch 23/25\nLoss: 291.1929\n\nOverall Metrics:\n  Accuracy: 0.6050\n  Precision: 0.5026\n  Recall: 0.0854\n  F1: 0.1420\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7729\n  Precision: 0.5073\n  Recall: 0.0974\n  F1: 0.1634\n  ROC AUC: 0.6986\nPneumonia:\n  Accuracy: 0.9207\n  Precision: 0.4167\n  Recall: 0.0202\n  F1: 0.0386\n  ROC AUC: 0.6685\nEdema:\n  Accuracy: 0.8385\n  Precision: 0.5837\n  Recall: 0.1386\n  F1: 0.2241\n  ROC AUC: 0.7706\n\nEpoch 24/25\nLoss: 290.8412\n\nOverall Metrics:\n  Accuracy: 0.6050\n  Precision: 0.5095\n  Recall: 0.0731\n  F1: 0.1258\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7729\n  Precision: 0.5092\n  Recall: 0.0853\n  F1: 0.1462\n  ROC AUC: 0.6988\nPneumonia:\n  Accuracy: 0.9205\n  Precision: 0.4118\n  Recall: 0.0227\n  F1: 0.0430\n  ROC AUC: 0.6658\nEdema:\n  Accuracy: 0.8384\n  Precision: 0.6074\n  Recall: 0.1114\n  F1: 0.1882\n  ROC AUC: 0.7712\n\nEpoch 25/25\nLoss: 290.1915\n\nOverall Metrics:\n  Accuracy: 0.6050\n  Precision: 0.5032\n  Recall: 0.0783\n  F1: 0.1313\n\nPer-condition Metrics:\nAtelectasis:\n  Accuracy: 0.7720\n  Precision: 0.4973\n  Recall: 0.1027\n  F1: 0.1702\n  ROC AUC: 0.6992\nPneumonia:\n  Accuracy: 0.9209\n  Precision: 0.3939\n  Recall: 0.0105\n  F1: 0.0205\n  ROC AUC: 0.6637\nEdema:\n  Accuracy: 0.8396\n  Precision: 0.6185\n  Recall: 0.1216\n  F1: 0.2032\n  ROC AUC: 0.7702\n\nBest F1 Score: 0.1420\n","output_type":"stream"}],"execution_count":6}]}